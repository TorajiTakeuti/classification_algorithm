import numpy as np
import sys
# 1. æƒ…å ±ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®è¨ˆç®—
def calculate_entropy(y):
    if len(y) == 0:
        return 0
    counts = np.bincount(y)
    probabilities = counts / len(y)
    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])

def ask_question(prompt):
    """è³ªå•ã‚’ã—ã¦ 1(yes) ã‹ 0(no) ã‚’è¿”ã™ã€‚ãã‚Œä»¥å¤–ã¯çµ‚äº†ã€‚"""
    answer = input(prompt).lower() # å°æ–‡å­—ã«çµ±ä¸€ã—ã¦åˆ¤å®š
    if answer == "yes":
        return 1
    elif answer == "no":
        return 0
    else:
        print("è³ªå•ã«ç­”ãˆã‚ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ï¼‰")
        sys.exit()

# 2. æ±ºå®šæœ¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
class DecisionTree:
    def __init__(self, max_depth=3):
        self.max_depth = max_depth
        self.tree = None

    def fit(self, X, y):
        """å­¦ç¿’ï¼ˆè¡Œåˆ—Xã¨ãƒ©ãƒ™ãƒ«yã‚’ä½¿ç”¨ã—ã¦æœ¨ã‚’æ§‹ç¯‰ï¼‰"""
        self.tree = self._build_tree(X, y, depth=0)

    def _build_tree(self, X, y, depth):
        """ã€å†å¸°ã€‘å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹"""
        num_samples, num_features = X.shape
        if len(np.unique(y)) == 1 or depth >= self.max_depth:
            return np.bincount(y).argmax()

        best_gain = -1
        best_split = None
        current_entropy = calculate_entropy(y)

        for feature_idx in range(num_features):
            values = np.unique(X[:, feature_idx])
            for threshold in values:
                left_indices = np.where(X[:, feature_idx] <= threshold)[0]
                right_indices = np.where(X[:, feature_idx] > threshold)[0]

                if len(left_indices) == 0 or len(right_indices) == 0:
                    continue

                e_left = calculate_entropy(y[left_indices])
                e_right = calculate_entropy(y[right_indices])
                n_l, n_r = len(left_indices), len(right_indices)
                child_entropy = (n_l / num_samples) * e_left + (n_r / num_samples) * e_right
                gain = current_entropy - child_entropy

                if gain > best_gain:
                    best_gain = gain
                    best_split = (feature_idx, threshold, left_indices, right_indices)

        if best_gain > 0:
            idx, thr, left_idx, right_idx = best_split
            left_subtree = self._build_tree(X[left_idx], y[left_idx], depth + 1)
            right_subtree = self._build_tree(X[right_idx], y[right_idx], depth + 1)
            return {"feature": idx, "threshold": thr, "left": left_subtree, "right": right_subtree}
        
        return np.bincount(y).argmax()

    def predict(self, x):
        """äºˆæ¸¬ã®å…¥ã‚Šå£"""
        return self._predict_recursive(x, self.tree)

    def _predict_recursive(self, x, node):
        """ã€å†å¸°ã€‘æ§‹ç¯‰ã•ã‚ŒãŸæœ¨ã‚’è¾¿ã£ã¦äºˆæ¸¬ã‚’è¿”ã™"""
        if not isinstance(node, dict):
            return node
        
        feature_val = x[node['feature']]
        if feature_val <= node['threshold']:
            return self._predict_recursive(x, node['left'])
        else:
            return self._predict_recursive(x, node['right'])

# --- å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: [ã‚«ã‚µãŒæ»‘ã‚‰ã‹ã‹(0 or 1), åŒ‚ã„ãŒã‚ã‚‹ã‹(0 or 1)]
X_train = np.array([
    [0, 0], [0, 1], [1, 0], [1, 1], [0, 1], [1, 1]
])
y_train = np.array([0, 1, 0, 1, 1, 1])  # 0:é£Ÿç”¨, 1:æ¯’

# å­¦ç¿’
model = DecisionTree(max_depth=2)
model.fit(X_train, y_train)

print("--- å­¦ç¿’å®Œäº† ---")
print("æ§‹ç¯‰ã•ã‚ŒãŸæ±ºå®šæœ¨ï¼ˆè¾æ›¸æ§‹é€ ï¼‰:", model.tree)

# äºˆæ¸¬ã®ãƒ†ã‚¹ãƒˆ
val1 = ask_question("ã‚«ã‚µã¯æ»‘ã‚‰ã‹ã§ã™ã‹ï¼Ÿ(yes or no)")
val2 = ask_question("åŒ‚ã„ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ(yes or no)")
test_mushroom = np.array([val1, val2])

result = model.predict(test_mushroom)

print("\n--- äºˆæ¸¬ãƒ†ã‚¹ãƒˆ ---")
print(f"ç‰¹å¾´{test_mushroom} ã®ã‚­ãƒã‚³ã¯...")
print(f"çµæœ: {'âš ï¸ æ¯’ã‚­ãƒã‚³ã§ã™ï¼' if result == 1 else 'ğŸ„ é£Ÿç”¨ã‚­ãƒã‚³ã§ã™ã€‚'}")